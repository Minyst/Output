{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de2fdcca-24a6-409b-95d6-43d7503d1839",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import json\n",
    "\n",
    "service = Service(\"C:/Users/USER/Desktop/chromedriver-win64/chromedriver-win64/chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=service)  # 수정된 부분\n",
    "driver.implicitly_wait(2)  # 웹페이지 로딩 대기 시간 설정\n",
    "\n",
    "# ✅ 크롤링 json\n",
    "\n",
    "search_page = 4\n",
    "sort = 1  # 최신순\n",
    "keywords = [\"프리미어리그\", \"프리메라리가\", \"분데스리가\", \"세리에A\", \"리그앙\", \"챔피언스리그\", \"fa컵\"]\n",
    "data_list = []\n",
    "\n",
    "try:\n",
    "    for keyword in keywords:\n",
    "        for i in range(search_page):\n",
    "            start_num = 1 if i == 0 else (i * 10) + 1\n",
    "            url = f'https://search.naver.com/search.naver?where=news&query={keyword}&sort={sort}&start={start_num}'\n",
    "\n",
    "            driver.get(url)\n",
    "            time.sleep(3)\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "            articles = soup.select('ul.list_news > li')\n",
    "            for article in articles:\n",
    "                media_name = article.select_one('.info.press').text if article.select_one('.info.press') else \"Unknown\"\n",
    "                title = article.select_one('.news_tit').text if article.select_one('.news_tit') else \"Unknown\"\n",
    "                content = article.select_one('.dsc_wrap').text if article.select_one('.dsc_wrap') else \"Unknown\"\n",
    "                data_list.append({\"media_name\": media_name, \"title\": title, \"content\": content})\n",
    "\n",
    "    with open(\"output.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "        crawled_json = json.dump(data_list, file, indent=4, ensure_ascii=False)\n",
    "        \n",
    "    df = pd.DataFrame(data_list)\n",
    "    df.to_csv(\"output.csv\",index=False)\n",
    "\n",
    "finally:\n",
    "    driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
